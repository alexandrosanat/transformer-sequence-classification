{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a3e15f-b18c-421f-876d-9e88600cb249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f0d5cb-89c6-42b9-ae9d-d0424ce71102",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7423df98-e05f-4227-ad57-a1c275bb39bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.competition_download_file(\n",
    "    \"sentiment-analysis-on-movie-reviews\", \"train.tsv.zip\", path=\"./\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec985f-3833-4b85-b7e8-13adda0bdecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"train.tsv.zip\", \"r\") as zipref:\n",
    "    zipref.extractall(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad9276-7f20-46d5-b59b-26fe23a367ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a2efa5-3954-4778-a100-014a167d6cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\n",
    "    \"/Users/alexandros/Documents/Repos/transformer-sequence-classification/venv/lib/python3.9/site-packages/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9159015f-6d10-4d6d-a3be-2b1582de2313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from math import ceil\n",
    "from transformers import AutoTokenizer, TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d5f535c-fea5-4a85-a69c-03cbbc430df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d77cd4b6-32f7-43de-a7c0-aaa139345451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcfae7f3-6da5-4388-8c2d-6f365fd5fee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1        64           2  This quiet , introspective and entertaining in...   \n",
       "2        82           3  Even fans of Ismail Merchant 's work , I suspe...   \n",
       "3       117           4  A positively thrilling combination of ethnogra...   \n",
       "4       157           5  Aggressive self-glorification and a manipulati...   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          4  \n",
       "2          1  \n",
       "3          3  \n",
       "4          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset=\"SentenceId\", keep=\"first\", inplace=True, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b00b4536-43cc-4b86-a168-484883d294ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8529"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ea9a1a-7608-439d-aebf-e2c8839b7ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlen = df[\"Phrase\"].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1360296-4501-4130-a7e5-66d645de3a9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jy/4cv6n2jn6hn219lh9yjycmfc0000gn/T/ipykernel_7901/375597678.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"darkgrid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.histplot(seqlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb617fd3-faef-49b9-81ad-2aa97d1da12c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Encode Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee46c653-968b-44a3-9a81-59a8b96ad6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbeb0041-d3d8-4276-ab64-e1242d492b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db2c57b0-6114-4bab-830f-02468cc14f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 19:53:11.797982: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-12-29 19:53:11.798177: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.encode_plus(\n",
    "    \"hello world\",\n",
    "    max_length=50,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    add_special_tokens=True,\n",
    "    return_token_type_ids=False,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors=\"tf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29aa88c3-ae79-4dd0-b813-d428b5a6395b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 50), dtype=int32, numpy=\n",
       "array([[  101, 19082,  1362,   102,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 50), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03b94b62-158a-4dde-b79e-69852cd472c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.batch_encode_plus(\n",
    "    df[\"Phrase\"].to_list(),\n",
    "    max_length=50,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    add_special_tokens=True,\n",
    "    return_token_type_ids=False,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors=\"tf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fbca123-91b9-40d7-96b4-6a6a91879921",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xids, Xmask = tokens[\"input_ids\"], tokens[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c5e5e81-b0dc-4b8e-b114-1b0f97add433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8529, 50), dtype=int32, numpy=\n",
       "array([[ 101,  138, 1326, ...,    0,    0,    0],\n",
       "       [ 101, 1188, 3589, ...,    0,    0,    0],\n",
       "       [ 101, 2431, 3899, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 101,  118,  149, ...,    0,    0,    0],\n",
       "       [ 101, 1109, 2523, ...,    0,    0,    0],\n",
       "       [ 101, 1109, 1273, ...,    0,    0,    0]], dtype=int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baad257e-76e7-46da-b8cc-958930582b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8529, 50), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a60e0f46-7ca1-494b-bac9-18738f9c6310",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_arr = df[\"Sentiment\"].values\n",
    "\n",
    "labels = np.zeros((sentiment_arr.size, sentiment_arr.max() + 1), dtype=int)\n",
    "\n",
    "# replacing 0 with a 1 at the index of the original array\n",
    "labels[np.arange(sentiment_arr.size), sentiment_arr] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5053d13e-c91a-4e6d-b1a0-6d512a3cbc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d65d194f-ff65-43a1-a49a-c8038bca2178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8529, 5), dtype=int32, numpy=\n",
       "array([[0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_tf = tf.convert_to_tensor(labels, dtype=\"int32\")\n",
    "labels_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4eae324b-2c6d-4845-b314-85f8620a6c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90263542-8605-41d1-9118-e40a3d055358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((50,), (50,), (5,)), types: (tf.int32, tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07d57e1f-01bb-433d-9c33-13e9322e2c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
      "array([  101,   138,  1326,  1104, 13936, 25265, 16913, 15107,  1103,\n",
      "        8050,  2553,  1115,  1184,  1110,  1363,  1111,  1103, 20398,\n",
      "        1110,  1145,  1363,  1111,  1103,   176,  9900,   117,  1199,\n",
      "        1104,  1134,  5411,  1821, 14225,  1133,  3839,  1104,  1134,\n",
      "        7919,  1106,  1277,  1104,   170,  1642,   119,   102,     0,\n",
      "           0,     0,     0,     0,     0], dtype=int32)>, <tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 0, 0, 0, 0, 0], dtype=int32)>, <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 0, 0, 0], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9833b85-2137-490c-829a-218251be13bb",
   "metadata": {},
   "source": [
    "TensorFlow expects input data as Dataset to be in tuple format. Where 0 index is input values and 1 is labels. We are using 2 inputs so within input we need to have a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fef0f65-f1d1-4fec-a2e2-33da7844ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func(input_ids, masks, labels):\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": masks}, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4addc652-2d59-4611-a14f-61e55f82737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(map_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc83189e-fd3b-4314-abd5-7375d2001ff8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': <tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
      "array([  101,   138,  1326,  1104, 13936, 25265, 16913, 15107,  1103,\n",
      "        8050,  2553,  1115,  1184,  1110,  1363,  1111,  1103, 20398,\n",
      "        1110,  1145,  1363,  1111,  1103,   176,  9900,   117,  1199,\n",
      "        1104,  1134,  5411,  1821, 14225,  1133,  3839,  1104,  1134,\n",
      "        7919,  1106,  1277,  1104,   170,  1642,   119,   102,     0,\n",
      "           0,     0,     0,     0,     0], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 0, 0, 0, 0, 0], dtype=int32)>}, <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 0, 0, 0], dtype=int32)>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 19:53:30.280101: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-12-29 19:53:30.280608: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8b03baa-1777-4db9-97fb-c77216ae8158",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93ad96b0-f688-4b74-a96c-a9ed095070e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(10_000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d9ea494-d40d-4574-b0c7-0bf96e17e41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': <tf.Tensor: shape=(32, 50), dtype=int32, numpy=\n",
      "array([[  101, 25233,   112, ...,     0,     0,     0],\n",
      "       [  101,   138,  1554, ...,     0,     0,     0],\n",
      "       [  101,   146,  1198, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [  101,   146,  1108, ...,     0,     0,     0],\n",
      "       [  101,  1337,  4054, ...,     0,     0,     0],\n",
      "       [  101,  4435,  1150, ...,     0,     0,     0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(32, 50), dtype=int32, numpy=\n",
      "array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}, <tf.Tensor: shape=(32, 5), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1],\n",
      "       [1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 1],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 1]], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5301d24-fd25-4fdf-9c33-429936b52515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS_LEN = dataset.cardinality().numpy()\n",
    "DS_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20207be2-a348-438f-93ea-e42899481434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NO_BATCHES = ceil(DS_LEN / 32)\n",
    "NO_BATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2030ced5-818a-4f13-b0c0-0ca63e07a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = 0.9\n",
    "\n",
    "train = dataset.take(round(NO_BATCHES * SPLIT))\n",
    "val = dataset.skip(round(NO_BATCHES * SPLIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1976913b-48a1-4bde-beff-6fbb39ac9d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({input_ids: (None, 50), attention_mask: (None, 50)}, (None, 5)), types: ({input_ids: tf.int32, attention_mask: tf.int32}, tf.int32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1925141f-0144-4dc8-aad8-a818575c9488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert = TFAutoModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6638c9-1635-4277-8891-87931ce507ea",
   "metadata": {},
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe128f8a-1aab-4404-a3ef-01a49c3064af",
   "metadata": {},
   "source": [
    "Define the input layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2b363fb-6b91-4663-aea6-fadc29f124db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention, name needs to be the same as in previously defined dict\n",
    "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN,), name=\"input_ids\", dtype=\"int32\")\n",
    "mask = tf.keras.layers.Input(shape=(SEQ_LEN,), name=\"attention_mask\", dtype=\"int32\")\n",
    "\n",
    "#input_ids = tf.keras.layers.Reshape([-1])(input_ids)\n",
    "#mask = tf.keras.layers.Reshape([-1])(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8adc78b2-ada7-4c8b-8c2d-490f6752c555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 50) dtype=int32 (created by layer 'input_ids')>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b257ab-9b4e-470a-9383-4bb9dd111efa",
   "metadata": {},
   "source": [
    "Bert takes in two inputs and returns 3 outputs from last layer of Bert model. The second tensor is the pooler output (last hidden state ran over activation function and then pooled - can be used directly for classification) which we're going to ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ce91279-c8fa-427c-83a8-a62d3022de57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/alexandros/miniforge3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    }
   ],
   "source": [
    "embeddings = bert(input_ids, attention_mask=mask)[0]\n",
    "\n",
    "X = tf.keras.layers.GlobalMaxPooling1D()(embeddings)\n",
    "X = tf.keras.layers.BatchNormalization()(X)\n",
    "X = tf.keras.layers.Dense(64, activation='relu')(X)\n",
    "X = tf.keras.layers.Dropout(0.1)(X)\n",
    "X = tf.keras.layers.Dense(32, activation='relu')(X)\n",
    "y = tf.keras.layers.Dense(5, activation='softmax', name='outputs')(X)\n",
    "\n",
    "# define input and output layers of our model\n",
    "model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c523c44-373b-4f06-95d7-230fdf6e1d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "baa351ec-172f-40df-8228-95d1fead5327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 108310272   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 768)          0           tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 768)          3072        global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           49216       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           2080        dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 5)            165         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 108,364,805\n",
      "Trainable params: 52,997\n",
      "Non-trainable params: 108,311,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b8a4fc1-b537-43cb-baf5-61538b139f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a7baf63-fb26-4b4b-90cd-4f465cf6e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a26566-c5d6-456c-849c-f9f337fd6a8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(train, validation_data=val, epochs=140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce496ad-c803-4c54-93ee-fdf46a8b7f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
