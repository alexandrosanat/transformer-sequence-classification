{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a3e15f-b18c-421f-876d-9e88600cb249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f0d5cb-89c6-42b9-ae9d-d0424ce71102",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7423df98-e05f-4227-ad57-a1c275bb39bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.competition_download_file(\n",
    "    \"sentiment-analysis-on-movie-reviews\", \"train.tsv.zip\", path=\"./\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec985f-3833-4b85-b7e8-13adda0bdecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"train.tsv.zip\", \"r\") as zipref:\n",
    "    zipref.extractall(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad9276-7f20-46d5-b59b-26fe23a367ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a2efa5-3954-4778-a100-014a167d6cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\n",
    "    \"/Users/alexandros/Documents/Repos/transformer-sequence-classification/venv/lib/python3.9/site-packages/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0ddcc07d-7c6e-4dad-bf41-c2691e9104ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: nb-black in ./venv/lib/python3.9/site-packages (1.0.7)\n",
      "Requirement already satisfied: black>='19.3' in ./venv/lib/python3.9/site-packages (from nb-black) (22.12.0)\n",
      "Requirement already satisfied: ipython in ./venv/lib/python3.9/site-packages (from nb-black) (8.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in ./venv/lib/python3.9/site-packages (from black>='19.3'->nb-black) (4.4.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in ./venv/lib/python3.9/site-packages (from black>='19.3'->nb-black) (0.10.3)\n",
      "Requirement already satisfied: platformdirs>=2 in ./venv/lib/python3.9/site-packages (from black>='19.3'->nb-black) (2.6.0)\n",
      "Requirement already satisfied: click>=8.0.0 in ./venv/lib/python3.9/site-packages (from black>='19.3'->nb-black) (8.1.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in ./venv/lib/python3.9/site-packages (from black>='19.3'->nb-black) (0.4.3)\n",
      "Requirement already satisfied: tomli>=1.1.0 in ./venv/lib/python3.9/site-packages (from black>='19.3'->nb-black) (2.0.1)\n",
      "Requirement already satisfied: pickleshare in ./venv/lib/python3.9/site-packages (from ipython->nb-black) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in ./venv/lib/python3.9/site-packages (from ipython->nb-black) (3.0.36)\n",
      "Requirement already satisfied: stack-data in ./venv/lib/python3.9/site-packages (from ipython->nb-black) (0.6.2)\n",
      "Requirement already satisfied: jedi>=0.16 in ./venv/lib/python3.9/site-packages (from ipython->nb-black) (0.18.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./venv/lib/python3.9/site-packages (from ipython->nb-black) (0.1.6)\n",
      "Requirement already satisfied: pexpect>4.3 in ./venv/lib/python3.9/site-packages (from ipython->nb-black) (4.8.0)\n",
      "Requirement already satisfied: appnope in ./venv/lib/python3.9/site-packages (from ipython->nb-black) (0.1.3)\n",
      "Requirement already satisfied: backcall in ./venv/lib/python3.9/site-packages (from ipython->nb-black) (0.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./venv/lib/python3.9/site-packages (from ipython->nb-black) (2.13.0)\n",
      "Requirement already satisfied: traitlets>=5 in ./venv/lib/python3.9/site-packages (from ipython->nb-black) (5.8.0)\n",
      "Requirement already satisfied: decorator in ./venv/lib/python3.9/site-packages (from ipython->nb-black) (5.1.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in ./venv/lib/python3.9/site-packages (from jedi>=0.16->ipython->nb-black) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./venv/lib/python3.9/site-packages (from pexpect>4.3->ipython->nb-black) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./venv/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython->nb-black) (0.2.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./venv/lib/python3.9/site-packages (from stack-data->ipython->nb-black) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./venv/lib/python3.9/site-packages (from stack-data->ipython->nb-black) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in ./venv/lib/python3.9/site-packages (from stack-data->ipython->nb-black) (0.2.2)\n",
      "Requirement already satisfied: six in ./venv/lib/python3.9/site-packages (from asttokens>=2.1.0->stack-data->ipython->nb-black) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nb-black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9159015f-6d10-4d6d-a3be-2b1582de2313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from math import ceil\n",
    "from transformers import AutoTokenizer, TFAutoModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5d5f535c-fea5-4a85-a69c-03cbbc430df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d77cd4b6-32f7-43de-a7c0-aaa139345451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bcfae7f3-6da5-4388-8c2d-6f365fd5fee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1        64           2  This quiet , introspective and entertaining in...   \n",
       "2        82           3  Even fans of Ismail Merchant 's work , I suspe...   \n",
       "3       117           4  A positively thrilling combination of ethnogra...   \n",
       "4       157           5  Aggressive self-glorification and a manipulati...   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          4  \n",
       "2          1  \n",
       "3          3  \n",
       "4          1  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset=\"SentenceId\", keep=\"first\", inplace=True, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b00b4536-43cc-4b86-a168-484883d294ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8529"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "71ea9a1a-7608-439d-aebf-e2c8839b7ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlen = df[\"Phrase\"].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1360296-4501-4130-a7e5-66d645de3a9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jy/4cv6n2jn6hn219lh9yjycmfc0000gn/T/ipykernel_15559/375597678.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"darkgrid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.histplot(seqlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb617fd3-faef-49b9-81ad-2aa97d1da12c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Encode Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ee46c653-968b-44a3-9a81-59a8b96ad6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dbeb0041-d3d8-4276-ab64-e1242d492b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "db2c57b0-6114-4bab-830f-02468cc14f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode_plus(\n",
    "    \"hello world\",\n",
    "    max_length=SEQ_LEN,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    add_special_tokens=True,\n",
    "    return_token_type_ids=False,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors=\"tf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "29aa88c3-ae79-4dd0-b813-d428b5a6395b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 32), dtype=int32, numpy=\n",
       "array([[  101, 19082,  1362,   102,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 32), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "03b94b62-158a-4dde-b79e-69852cd472c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.batch_encode_plus(\n",
    "    df[\"Phrase\"].to_list(),\n",
    "    max_length=SEQ_LEN,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    add_special_tokens=True,\n",
    "    return_token_type_ids=False,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors=\"tf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6fbca123-91b9-40d7-96b4-6a6a91879921",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xids, Xmask = tokens[\"input_ids\"], tokens[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0c5e5e81-b0dc-4b8e-b114-1b0f97add433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8529, 32), dtype=int32, numpy=\n",
       "array([[ 101,  138, 1326, ..., 5411, 1821,  102],\n",
       "       [ 101, 1188, 3589, ...,    0,    0,    0],\n",
       "       [ 101, 2431, 3899, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 101,  118,  149, ...,    0,    0,    0],\n",
       "       [ 101, 1109, 2523, ...,    0,    0,    0],\n",
       "       [ 101, 1109, 1273, ..., 2897,  119,  102]], dtype=int32)>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "baad257e-76e7-46da-b8cc-958930582b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8529, 32), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 1, 1, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0b0e52f2-485a-4772-a05f-158df921aa67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 1, ..., 1, 1, 2])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a60e0f46-7ca1-494b-bac9-18738f9c6310",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_arr = df[\"Sentiment\"].values\n",
    "\n",
    "labels = np.zeros((sentiment_arr.size, sentiment_arr.max() + 1), dtype=int)\n",
    "\n",
    "# replacing 0 with a 1 at the index of the original array\n",
    "labels[np.arange(sentiment_arr.size), sentiment_arr] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5053d13e-c91a-4e6d-b1a0-6d512a3cbc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d65d194f-ff65-43a1-a49a-c8038bca2178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8529, 5), dtype=int32, numpy=\n",
       "array([[0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_tf = tf.convert_to_tensor(labels, dtype=\"int32\")\n",
    "labels_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4eae324b-2c6d-4845-b314-85f8620a6c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "90263542-8605-41d1-9118-e40a3d055358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((32,), (32,), (5,)), types: (tf.int32, tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "07d57e1f-01bb-433d-9c33-13e9322e2c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([  101,   138,  1326,  1104, 13936, 25265, 16913, 15107,  1103,\n",
      "        8050,  2553,  1115,  1184,  1110,  1363,  1111,  1103, 20398,\n",
      "        1110,  1145,  1363,  1111,  1103,   176,  9900,   117,  1199,\n",
      "        1104,  1134,  5411,  1821,   102], dtype=int32)>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>, <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 0, 0, 0], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9833b85-2137-490c-829a-218251be13bb",
   "metadata": {},
   "source": [
    "TensorFlow expects input data as Dataset to be in tuple format. Where 0 index is input values and 1 is labels. We are using 2 inputs so within input we need to have a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5fef0f65-f1d1-4fec-a2e2-33da7844ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func(input_ids, masks, labels):\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": masks}, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4addc652-2d59-4611-a14f-61e55f82737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(map_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fc83189e-fd3b-4314-abd5-7375d2001ff8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([  101,   138,  1326,  1104, 13936, 25265, 16913, 15107,  1103,\n",
      "        8050,  2553,  1115,  1184,  1110,  1363,  1111,  1103, 20398,\n",
      "        1110,  1145,  1363,  1111,  1103,   176,  9900,   117,  1199,\n",
      "        1104,  1134,  5411,  1821,   102], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>}, <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 0, 0, 0], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a8b03baa-1777-4db9-97fb-c77216ae8158",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "93ad96b0-f688-4b74-a96c-a9ed095070e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(100_000).batch(BATCH_SIZE) #.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0d9ea494-d40d-4574-b0c7-0bf96e17e41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': <tf.Tensor: shape=(32, 32), dtype=int32, numpy=\n",
      "array([[  101,  1249,  5805, ...,     0,     0,     0],\n",
      "       [  101, 12515,   165, ..., 15538,  1105,   102],\n",
      "       [  101, 12515,   118, ...,  2302,  3404,   102],\n",
      "       ...,\n",
      "       [  101,  1135, 12246, ...,     0,     0,     0],\n",
      "       [  101,  1135,   112, ...,  2332,  5986,   102],\n",
      "       [  101, 13719,  6758, ...,     0,     0,     0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(32, 32), dtype=int32, numpy=\n",
      "array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}, <tf.Tensor: shape=(32, 5), dtype=int32, numpy=\n",
      "array([[1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 1],\n",
      "       [1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 1],\n",
      "       [0, 1, 0, 0, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 1, 0],\n",
      "       [0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 0, 1],\n",
      "       [0, 0, 1, 0, 0],\n",
      "       [0, 0, 1, 0, 0]], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e5301d24-fd25-4fdf-9c33-429936b52515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS_LEN = dataset.cardinality().numpy()\n",
    "DS_LEN = len([0 for batch in dataset])\n",
    "DS_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "20207be2-a348-438f-93ea-e42899481434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NO_BATCHES = ceil(DS_LEN / BATCH_SIZE)\n",
    "NO_BATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2030ced5-818a-4f13-b0c0-0ca63e07a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = 0.9\n",
    "\n",
    "train = dataset.take(round(DS_LEN * SPLIT))  #.repeat(EPOCHS * STEPS_PER_EPOCH)\n",
    "val = dataset.skip(round(DS_LEN * SPLIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1976913b-48a1-4bde-beff-6fbb39ac9d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({input_ids: (None, 32), attention_mask: (None, 32)}, (None, 5)), types: ({input_ids: tf.int32, attention_mask: tf.int32}, tf.int32)>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1925141f-0144-4dc8-aad8-a818575c9488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert = TFAutoModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6638c9-1635-4277-8891-87931ce507ea",
   "metadata": {},
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe128f8a-1aab-4404-a3ef-01a49c3064af",
   "metadata": {},
   "source": [
    "Define the input layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b2b363fb-6b91-4663-aea6-fadc29f124db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention, name needs to be the same as in previously defined dict\n",
    "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN,), name=\"input_ids\", dtype=\"int32\")\n",
    "mask = tf.keras.layers.Input(shape=(SEQ_LEN,), name=\"attention_mask\", dtype=\"int32\")\n",
    "\n",
    "#input_ids = tf.keras.layers.Reshape([-1])(input_ids)\n",
    "#mask = tf.keras.layers.Reshape([-1])(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b257ab-9b4e-470a-9383-4bb9dd111efa",
   "metadata": {},
   "source": [
    "Bert takes in two inputs and returns 3 outputs from last layer of Bert model. The second tensor is the pooler output (last hidden state ran over activation function and then pooled - can be used directly for classification) which we're going to ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9ce91279-c8fa-427c-83a8-a62d3022de57",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = bert(input_ids, attention_mask=mask)[0]\n",
    "\n",
    "# Original Author: Ferry Djaja\n",
    "# https://djajafer.medium.com/multi-class-text-classification-with-keras-and-lstm-4c5525bef592\n",
    "X = tf.keras.layers.Dropout(0.1)(embeddings)\n",
    "X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(768))(X)\n",
    "y = tf.keras.layers.Dense(5, activation='softmax', name='outputs')(X)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids,mask], outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9c523c44-373b-4f06-95d7-230fdf6e1d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "baa351ec-172f-40df-8228-95d1fead5327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 32)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 32)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model_2 (TFBertModel)   TFBaseModelOutputWit 108310272   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)           (None, 32, 768)      0           tf_bert_model_2[4][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1536)         9443328     dropout_120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 5)            7685        bidirectional_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 117,761,285\n",
      "Trainable params: 9,451,013\n",
      "Non-trainable params: 108,310,272\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1b8a4fc1-b537-43cb-baf5-61538b139f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7a7baf63-fb26-4b4b-90cd-4f465cf6e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1e4251de-4192-4a57-8719-a0a66f5b4ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "STEPS_PER_EPOCH = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a26566-c5d6-456c-849c-f9f337fd6a8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-01 17:19:22.573817: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-01 17:19:25.571842: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-01 17:19:25.580338: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-01 17:19:26.122979: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-01 17:19:26.135005: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 172s 688ms/step - loss: 1.3463 - accuracy: 0.4154\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 163s 679ms/step - loss: 1.2116 - accuracy: 0.4799\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 164s 682ms/step - loss: 1.1617 - accuracy: 0.5040\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 165s 686ms/step - loss: 1.0886 - accuracy: 0.5368\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 173s 721ms/step - loss: 1.0202 - accuracy: 0.5655\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 169s 705ms/step - loss: 0.9132 - accuracy: 0.6164\n",
      "Epoch 7/10\n",
      " 63/240 [======>.......................] - ETA: 2:04 - loss: 0.7343 - accuracy: 0.7088"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, validation_data=val, epochs=EPOCHS, validation_freq=140)  #, steps_per_epoch=STEPS_PER_EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce496ad-c803-4c54-93ee-fdf46a8b7f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc2debe-01a4-4c14-a91c-a87ac247c43c",
   "metadata": {},
   "source": [
    "#### Making predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a1bf8f-13e1-447b-939d-748f4d1020f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68354a-3ba4-471a-93e7-814a88005782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(text):\n",
    "    tokens = tokenizer.encode_plus(\n",
    "    text,\n",
    "    max_length=SEQ_LEN,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    add_special_tokens=True,\n",
    "    return_token_type_ids=False,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors=\"tf\",\n",
    ")\n",
    "    return {\n",
    "        \"input_ids\": tf.cast(tokens[\"input_ids\"], tf.int32)\n",
    "        \"attention_mask\": tf.cast(tokens[\"attention_mask\"], tf.int32)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155663b2-43aa-44fd-99a3-d3748ce94a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = prep_data(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c5377-287a-43dc-8fcc-1428129f4b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model.predict(test_data)\n",
    "\n",
    "probs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
